"""
Modu≈Ç odpowiedzialny za stronƒô modelowania uczenia maszynowego w aplikacji Wine Dataset Analysis.
Rozszerzony o opcje wyboru rodzaju eksperymentu zgodnie z wymaganiami prowadzƒÖcego.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time

# Import modu≈Ç√≥w w≈Çasnych
from src.ml_modeler import ClassificationModel, ClusteringModel, AssociationRulesMiner
from src.data_loader import split_features_target
from src.utils import (
    format_classification_report, format_confusion_matrix,
    generate_model_parameter_description, get_column_types
)
from src.data_visualizer import create_feature_importance
from components.descriptions import (
    get_page_description, get_ml_model_description,
    get_model_parameter_description
)
from components.ui_helpers import show_info_box, section_header


def page_ml_modeling():
    """Wy≈õwietla stronƒô modelowania uczenia maszynowego."""

    # Pobierz opis strony
    page_info = get_page_description("ml_modeling")

    # Nag≈Ç√≥wek strony
    st.header(page_info["title"])
    st.markdown(page_info["description"])

    # Wprowadzenie do uczenia maszynowego
    with st.expander("‚ÑπÔ∏è O uczeniu maszynowym na danych Wine Dataset", expanded=True):
        st.markdown("""
        **Uczenie maszynowe** to technika analizy danych, kt√≥ra umo≈ºliwia systemom automatyczne uczenie siƒô i poprawianie
        na podstawie do≈õwiadczenia bez jawnego programowania.

        W kontek≈õcie zbioru danych Wine Dataset mo≈ºemy zastosowaƒá r√≥≈ºne techniki uczenia maszynowego:

        - **Klasyfikacja**: Przewidywanie klasy wina (1, 2 lub 3) na podstawie jego cech chemicznych
        - **Klastrowanie**: Grupowanie podobnych win bez wcze≈õniejszej wiedzy o ich klasach
        - **Regu≈Çy asocjacyjne**: Odkrywanie interesujƒÖcych relacji miƒôdzy cechami chemicznymi win

        Zbi√≥r danych Wine jest idealny do eksperymentowania z uczeniem maszynowym, poniewa≈º:
        - Jest stosunkowo ma≈Çy (178 pr√≥bek), co umo≈ºliwia szybkie trenowanie modeli
        - Zawiera 13 cech, co jest wystarczajƒÖco z≈Ço≈ºone, ale nie przyt≈ÇaczajƒÖce
        - Klasy sƒÖ do≈õƒá dobrze rozdzielone, co pozwala uzyskaƒá wysokƒÖ dok≈Çadno≈õƒá

        W tej sekcji mo≈ºesz trenowaƒá i ewaluowaƒá r√≥≈ºne modele uczenia maszynowego na zbiorze danych Wine.
        """)

    # Wyb√≥r kategorii modelu
    st.markdown("---")
    st.subheader("Wybierz typ modelowania")

    model_category = st.selectbox(
        "Kategoria modelu:",
        ["Klasyfikacja", "Klastrowanie", "Regu≈Çy asocjacyjne"],
        help="Wybierz typ modelowania uczenia maszynowego do zastosowania"
    )

    # Klasyfikacja
    if model_category == "Klasyfikacja":
        ml_info = get_ml_model_description("classification")
        section_header(ml_info["title"], "Przewidywanie klasy wina na podstawie cech chemicznych")

        with st.expander("‚ÑπÔ∏è O modelach klasyfikacyjnych"):
            st.markdown(ml_info["description"])

        # Sprawd≈∫, czy kolumna Class istnieje
        if 'Class' not in st.session_state.data.columns:
            st.error("Kolumna 'Class' nie istnieje w danych. Nie mo≈ºna wykonaƒá klasyfikacji.")
            return

        # Wyb√≥r modelu klasyfikacji
        model_type = st.selectbox(
            "Wybierz model klasyfikacji:",
            ["Random Forest (rf)", "K-Nearest Neighbors (knn)", "Support Vector Machine (svm)"],
            index=0,
            help="Wybierz algorytm klasyfikacji do zastosowania"
        )

        # Mapowanie wy≈õwietlanej nazwy na kod
        model_code = model_type.split(' ')[0].lower()
        if model_code == "random":
            model_code = "rf"
        elif model_code == "k-nearest":
            model_code = "knn"
        elif model_code == "support":
            model_code = "svm"

        # Parametry modelu
        st.subheader("Parametry modelu")

        with st.expander("‚ÑπÔ∏è Co to sƒÖ parametry modelu?"):
            st.markdown("""
            **Parametry modelu** (hiperparametry) to warto≈õci konfiguracyjne, kt√≥re kontrolujƒÖ zachowanie 
            algorytmu uczenia maszynowego. W≈Ça≈õciwy dob√≥r parametr√≥w mo≈ºe znacznie poprawiƒá wydajno≈õƒá modelu.

            Ka≈ºdy model ma inne parametry, kt√≥re wp≈ÇywajƒÖ na r√≥≈ºne aspekty jego dzia≈Çania:
            - Jak z≈Ço≈ºony jest model
            - Jak szybko siƒô uczy
            - Jak dobrze generalizuje na nowe dane

            Dostosowanie tych parametr√≥w do konkretnego problemu i danych nazywa siƒô **strojeniem hiperparametr√≥w**.
            """)

        # Pobierz opisy parametr√≥w dla wybranego modelu
        param_desc = generate_model_parameter_description(model_code)
        params = {}

        # Dynamicznie generuj widgety dla parametr√≥w modelu
        for param_name, param_info in param_desc.items():
            # Dodaj opis parametru
            st.markdown(f"**{param_info['name']}**")
            help_text = get_model_parameter_description(model_code, param_name)

            # Wybierz odpowiedni typ widgetu
            if 'options' in param_info:
                params[param_name] = st.selectbox(
                    f"Wybierz warto≈õƒá dla {param_info['name']}:",
                    param_info['options'],
                    index=param_info['options'].index(param_info['default']) if param_info['default'] in param_info[
                        'options'] else 0,
                    help=help_text
                )
            elif 'min' in param_info and 'max' in param_info:
                step = param_info.get('step', 1)
                params[param_name] = st.slider(
                    f"Ustaw warto≈õƒá dla {param_info['name']}:",
                    param_info['min'],
                    param_info['max'],
                    param_info['default'],
                    step=step,
                    help=help_text
                )

        # NOWA SEKCJA: Wyb√≥r rodzaju eksperymentu
        st.subheader("üß™ Rodzaj eksperymentu")

        with st.expander("‚ÑπÔ∏è O rodzajach eksperyment√≥w w uczeniu maszynowym", expanded=True):
            st.markdown("""
            **Rodzaj eksperymentu** okre≈õla spos√≥b, w jaki model bƒôdzie trenowany i ewaluowany:

            - **Train/Test Split**: Dzieli dane na zbi√≥r treningowy i testowy. Model uczony jest na zbiorze treningowym, a ewaluowany na testowym.
            - **Cross-Validation (k-fold)**: Dzieli dane na k czƒô≈õci, trenuje model k razy, ka≈ºdorazowo u≈ºywajƒÖc innej czƒô≈õci jako zbioru testowego.
            - **Leave-One-Out (LOO)**: Specjalny przypadek cross-validation, gdzie k = liczba pr√≥bek. Ka≈ºda pr√≥bka jest raz zbiorem testowym.

            **Zalety poszczeg√≥lnych metod:**
            - **Train/Test**: Szybki, prosty, dobry dla du≈ºych zbior√≥w danych
            - **Cross-Validation**: Bardziej niezawodny, lepiej wykorzystuje dane, mniej podatny na przypadkowo≈õƒá podzia≈Çu
            - **Leave-One-Out**: Maksymalnie wykorzystuje dane, najlepszy dla ma≈Çych zbior√≥w, ale czasoch≈Çonny
            """)

        # Radio button do wyboru eksperymentu
        experiment_type = st.radio(
            "Wybierz rodzaj eksperymentu:",
            ["Train/Test Split", "Cross-Validation (k-fold)", "Leave-One-Out (LOO)"],
            index=0,
            help="Wybierz metodƒô podzia≈Çu danych do treningu i ewaluacji modelu"
        )

        # Parametry eksperymentu w zale≈ºno≈õci od wyboru
        experiment_params = {}

        if experiment_type == "Train/Test Split":
            col1, col2 = st.columns(2)
            with col1:
                experiment_params['test_size'] = st.slider(
                    "Proporcja zbioru testowego:",
                    min_value=0.1,
                    max_value=0.5,
                    value=0.2,
                    step=0.05,
                    help="Jaka czƒô≈õƒá danych zostanie u≈ºyta do testowania (reszta do treningu)"
                )
            with col2:
                experiment_params['random_state'] = st.number_input(
                    "Ziarno losowo≈õci:",
                    min_value=1,
                    max_value=999,
                    value=42,
                    help="Zapewnia powtarzalno≈õƒá wynik√≥w"
                )

        elif experiment_type == "Cross-Validation (k-fold)":
            col1, col2 = st.columns(2)
            with col1:
                experiment_params['cv_folds'] = st.slider(
                    "Liczba fa≈Çd (k):",
                    min_value=3,
                    max_value=10,
                    value=5,
                    help="Na ile czƒô≈õci podzieliƒá dane (typowo 5 lub 10)"
                )
            with col2:
                experiment_params['random_state'] = st.number_input(
                    "Ziarno losowo≈õci:",
                    min_value=1,
                    max_value=999,
                    value=42,
                    help="Zapewnia powtarzalno≈õƒá wynik√≥w",
                    key="cv_random_state"
                )

        else:  # Leave-One-Out
            st.info("Leave-One-Out nie wymaga dodatkowych parametr√≥w. Ka≈ºda pr√≥bka bƒôdzie raz zbiorem testowym.")
            experiment_params['cv_folds'] = len(st.session_state.data)  # LOO = n-fold CV gdzie n = liczba pr√≥bek

        # Opcja skalowania danych
        st.subheader("Przygotowanie danych")

        scale_data = st.checkbox(
            "Skaluj dane przed trenowaniem",
            value=True,
            help="Zalecane dla wiƒôkszo≈õci modeli, szczeg√≥lnie SVM i KNN"
        )

        # Tworzenie i trening modelu
        if st.button("Trenuj model", key="train_classification"):
            # Przygotowanie danych
            X, y = split_features_target(st.session_state.data)

            # Dodaj pasek postƒôpu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Trening modelu..."):
                # Aktualizuj pasek postƒôpu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Trening modelu {model_type}... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                model = ClassificationModel(model_code)

                # Wykonaj eksperyment w zale≈ºno≈õci od wyboru
                if experiment_type == "Train/Test Split":
                    # Przygotowanie danych
                    model.prepare_data(X, y,
                                     test_size=experiment_params['test_size'],
                                     random_state=experiment_params['random_state'])

                    # Trening modelu
                    results = model.train(params)
                    results['experiment_type'] = 'train_test_split'

                elif experiment_type == "Cross-Validation (k-fold)":
                    # Cross-validation
                    results = model.cross_validate(X, y, params,
                                                 cv_folds=experiment_params['cv_folds'],
                                                 random_state=experiment_params['random_state'])
                    results['experiment_type'] = 'cross_validation'

                else:  # Leave-One-Out
                    # Leave-One-Out (LOO = n-fold CV)
                    results = model.cross_validate(X, y, params,
                                                 cv_folds=len(X),  # LOO
                                                 random_state=experiment_params.get('random_state', 42))
                    results['experiment_type'] = 'leave_one_out'

                # Ukryj pasek postƒôpu i tekst statusu po zako≈Ñczeniu
                progress_bar.empty()
                status_text.empty()

                # Wy≈õwietl komunikat o sukcesie
                st.success(f"Model {model_type} zosta≈Ç pomy≈õlnie wytrenowany u≈ºywajƒÖc metody: {experiment_type}!")

                # Wy≈õwietlenie wynik√≥w w zale≈ºno≈õci od typu eksperymentu
                display_classification_results(results, experiment_type, model_type)

    # Klastrowanie
    elif model_category == "Klastrowanie":
        ml_info = get_ml_model_description("clustering")
        section_header(ml_info["title"], "Grupowanie win o podobnych cechach chemicznych")

        with st.expander("‚ÑπÔ∏è O modelach klastrowania"):
            st.markdown(ml_info["description"])

        # Wyb√≥r modelu klastrowania
        model_type = st.selectbox(
            "Wybierz model klastrowania:",
            ["K-Means", "DBSCAN"],
            index=0,
            help="Wybierz algorytm klastrowania do zastosowania"
        )

        # Mapowanie wy≈õwietlanej nazwy na kod
        model_code = model_type.lower()

        # Parametry modelu
        st.subheader("Parametry modelu")

        # Pobierz opisy parametr√≥w dla wybranego modelu
        param_desc = generate_model_parameter_description(model_code)
        params = {}

        # Dynamicznie generuj widgety dla parametr√≥w modelu
        for param_name, param_info in param_desc.items():
            # Dodaj opis parametru
            st.markdown(f"**{param_info['name']}**")
            help_text = get_model_parameter_description(model_code, param_name)

            # Wybierz odpowiedni typ widgetu
            if 'options' in param_info:
                params[param_name] = st.selectbox(
                    f"Wybierz warto≈õƒá dla {param_info['name']}:",
                    param_info['options'],
                    index=param_info['options'].index(param_info['default']) if param_info['default'] in param_info[
                        'options'] else 0,
                    help=help_text
                )
            elif 'min' in param_info and 'max' in param_info:
                step = param_info.get('step', 1)
                params[param_name] = st.slider(
                    f"Ustaw warto≈õƒá dla {param_info['name']}:",
                    param_info['min'],
                    param_info['max'],
                    param_info['default'],
                    step=step,
                    help=help_text
                )

        # Wyb√≥r cech do klastrowania
        st.subheader("Wyb√≥r cech")

        # Pobierz kolumny numeryczne
        column_types = get_column_types(st.session_state.data)
        numeric_cols = column_types.get('numeric', [])

        # Usu≈Ñ kolumnƒô Class z listy, je≈õli istnieje
        if 'Class' in numeric_cols:
            numeric_cols.remove('Class')

        # Widget do wyboru cech
        selected_features = st.multiselect(
            "Wybierz cechy do klastrowania:",
            numeric_cols,
            default=numeric_cols[:5] if len(numeric_cols) > 5 else numeric_cols,
            help="Wybierz cechy, na podstawie kt√≥rych bƒôdƒÖ grupowane wina"
        )

        # Opcja por√≥wnania z prawdziwymi klasami
        compare_with_true = st.checkbox(
            "Por√≥wnaj z prawdziwymi klasami",
            value=True,
            help="Por√≥wnaj znalezione klastry z prawdziwymi klasami win (je≈õli dostƒôpne)"
        )

        # Przycisk do trenowania modelu
        if st.button("Wykonaj klastrowanie", key="train_clustering") and selected_features:
            # Przygotowanie danych
            X = st.session_state.data[selected_features]

            # Dodaj pasek postƒôpu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Klastrowanie danych..."):
                # Aktualizuj pasek postƒôpu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Wykonywanie klastrowania {model_type}... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                model = ClusteringModel(model_code)

                # Przygotowanie danych
                model.prepare_data(X)

                # Znajdowanie optymalnej liczby klastr√≥w dla K-Means
                if model_code == 'k-means':
                    st.subheader("Znajdowanie optymalnej liczby klastr√≥w")
                    max_clusters = st.slider(
                        "Maksymalna liczba klastr√≥w do sprawdzenia:",
                        min_value=2,
                        max_value=15,
                        value=10,
                        help="Wiƒôksza liczba = d≈Çu≈ºszy czas oblicze≈Ñ"
                    )

                    with st.spinner("Szukanie optymalnej liczby klastr√≥w..."):
                        optimal_results = model.find_optimal_clusters(max_clusters)

                        # Wykres metody ≈Çokcia (inertia)
                        st.subheader("Metoda ≈Çokcia (inertia)")

                        with st.expander("‚ÑπÔ∏è Jak interpretowaƒá metodƒô ≈Çokcia?"):
                            st.markdown("""
                            **Metoda ≈Çokcia** pomaga znale≈∫ƒá optymalnƒÖ liczbƒô klastr√≥w poprzez wykres inercji
                            (sumy kwadrat√≥w odleg≈Ço≈õci punkt√≥w od ich centroid√≥w) w zale≈ºno≈õci od liczby klastr√≥w.

                            Szukamy "≈Çokcia" na wykresie - punktu, w kt√≥rym dodanie kolejnego klastra daje 
                            znacznie mniejszy spadek inercji. Ten punkt sugeruje optymalnƒÖ liczbƒô klastr√≥w.
                            """)

                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.plot(optimal_results["k_values"], optimal_results["inertias"], 'o-')
                        ax.set_xlabel('Liczba klastr√≥w (k)')
                        ax.set_ylabel('Inertia')
                        ax.set_title('Metoda ≈Çokcia dla okre≈õlenia optymalnej liczby klastr√≥w')
                        ax.grid(True)
                        st.pyplot(fig)

                        # Wykres wsp√≥≈Çczynnika silhouette
                        st.subheader("Wsp√≥≈Çczynnik silhouette")

                        with st.expander("‚ÑπÔ∏è Jak interpretowaƒá wsp√≥≈Çczynnik silhouette?"):
                            st.markdown("""
                            **Wsp√≥≈Çczynnik silhouette** mierzy, jak podobny jest obiekt do w≈Çasnego klastra
                            w por√≥wnaniu do innych klastr√≥w. Warto≈õci wahajƒÖ siƒô od -1 do 1:

                            - **Warto≈õci bliskie 1**: Obiekt jest dobrze przypisany do swojego klastra
                            - **Warto≈õci bliskie 0**: Obiekt jest na granicy miƒôdzy klastrami
                            - **Warto≈õci bliskie -1**: Obiekt prawdopodobnie jest w z≈Çym klastrze

                            Wy≈ºsze warto≈õci ≈õrednie wskazujƒÖ lepszƒÖ konfiguracjƒô klastr√≥w.
                            """)

                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.plot(optimal_results["k_values"], optimal_results["silhouettes"], 'o-')
                        ax.set_xlabel('Liczba klastr√≥w (k)')
                        ax.set_ylabel('Wsp√≥≈Çczynnik silhouette')
                        ax.set_title('Wsp√≥≈Çczynnik silhouette dla okre≈õlenia optymalnej liczby klastr√≥w')
                        ax.grid(True)
                        st.pyplot(fig)

                        # Informacja o optymalnej liczbie klastr√≥w
                        st.info(
                            f"Optymalna liczba klastr√≥w na podstawie wsp√≥≈Çczynnika silhouette: {optimal_results['optimal_k']}")

                        # Aktualizacja liczby klastr√≥w
                        params['n_clusters'] = optimal_results['optimal_k']

                # Trening modelu
                results = model.train(params)

                # Ukryj pasek postƒôpu i tekst statusu po zako≈Ñczeniu
                progress_bar.empty()
                status_text.empty()

                # Wy≈õwietl komunikat o sukcesie
                st.success(f"Klastrowanie {model_type} zosta≈Ço pomy≈õlnie wykonane!")

                # Dodaj etykiety klastr√≥w do danych
                cluster_labels = model.get_clusters()
                clustering_result = X.copy()
                clustering_result['Klaster'] = cluster_labels

                # Je≈õli istnieje kolumna Class, dodaj jƒÖ do wynik√≥w
                if 'Class' in st.session_state.data.columns and compare_with_true:
                    clustering_result['Prawdziwa_klasa'] = st.session_state.data['Class']

                # Wy≈õwietlenie wynik√≥w
                st.subheader("Wyniki klastrowania")

                # Podstawowe informacje
                n_clusters = results['n_clusters']
                st.write(f"Liczba klastr√≥w: {n_clusters}")

                # Liczba pr√≥bek w ka≈ºdym klastrze
                st.subheader("Rozk≈Çad klastr√≥w")
                cluster_sizes = pd.DataFrame.from_dict(
                    results['cluster_sizes'],
                    orient='index',
                    columns=['Liczba pr√≥bek']
                )
                cluster_sizes.index.name = 'Klaster'
                st.dataframe(cluster_sizes)

                # Wykres rozk≈Çadu klastr√≥w
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.bar(cluster_sizes.index.astype(str), cluster_sizes['Liczba pr√≥bek'])
                ax.set_xlabel('Klaster')
                ax.set_ylabel('Liczba pr√≥bek')
                ax.set_title('Rozk≈Çad pr√≥bek w klastrach')
                ax.grid(axis='y')
                st.pyplot(fig)

                # Dodatkowe informacje dla K-Means
                if model_code == 'k-means':
                    st.subheader("Inertia")
                    st.write(f"Inertia: {results['inertia']:.3f}")

                    with st.expander("‚ÑπÔ∏è Co to jest inertia?"):
                        st.markdown("""
                        **Inertia** to suma kwadrat√≥w odleg≈Ço≈õci ka≈ºdej pr√≥bki od centroidu jej klastra.

                        Mniejsza warto≈õƒá inertia oznacza, ≈ºe punkty sƒÖ bli≈ºej swoich centroid√≥w,
                        co sugeruje lepszy podzia≈Ç klastr√≥w.
                        """)

                # Wsp√≥≈Çczynnik silhouette (je≈õli dostƒôpny)
                if 'silhouette_score' in results:
                    st.subheader("Wsp√≥≈Çczynnik silhouette")

                    score = results['silhouette_score']
                    st.write(f"Wsp√≥≈Çczynnik silhouette: {score:.3f}")

                    # Interpretacja wyniku
                    if score > 0.7:
                        st.success("Silna struktura klastr√≥w.")
                    elif score > 0.5:
                        st.info("≈örednia struktura klastr√≥w.")
                    elif score > 0.25:
                        st.warning("S≈Çaba struktura klastr√≥w.")
                    else:
                        st.error("Brak znaczƒÖcej struktury klastr√≥w.")

                # Por√≥wnanie z prawdziwymi klasami (je≈õli dostƒôpne)
                if 'Class' in st.session_state.data.columns and compare_with_true:
                    st.subheader("Por√≥wnanie z prawdziwymi klasami")

                    # Tabela pokazujƒÖca liczbƒô win z ka≈ºdej klasy w ka≈ºdym klastrze
                    cross_tab = pd.crosstab(
                        clustering_result['Klaster'],
                        clustering_result['Prawdziwa_klasa'],
                        rownames=['Klaster'],
                        colnames=['Prawdziwa klasa']
                    )

                    st.dataframe(cross_tab)

                    # Wizualizacja por√≥wnania
                    fig, ax = plt.subplots(figsize=(10, 6))
                    cross_tab.plot(kind='bar', stacked=True, ax=ax)
                    ax.set_xlabel('Klaster')
                    ax.set_ylabel('Liczba pr√≥bek')
                    ax.set_title('Rozk≈Çad prawdziwych klas w klastrach')
                    ax.legend(title='Prawdziwa klasa')
                    st.pyplot(fig)

                    # Obliczanie czysto≈õci klastr√≥w
                    cluster_purity = np.sum([np.max(cross_tab.values[i]) for i in range(len(cross_tab))]) / np.sum(
                        cross_tab.values)
                    st.metric(
                        "Czysto≈õƒá klastr√≥w",
                        f"{cluster_purity:.3f}",
                        help="Procent pr√≥bek w ka≈ºdym klastrze nale≈ºƒÖcych do klasy najczƒô≈õciej wystƒôpujƒÖcej w tym klastrze"
                    )

                    with st.expander("‚ÑπÔ∏è Co to jest czysto≈õƒá klastr√≥w?"):
                        st.markdown("""
                        **Czysto≈õƒá klastr√≥w** (cluster purity) to miara, kt√≥ra pokazuje, jak dobrze klastry odpowiadajƒÖ prawdziwym klasom.

                        Dla ka≈ºdego klastra znajdujemy klasƒô, kt√≥ra wystƒôpuje w nim najczƒô≈õciej. Nastƒôpnie sumujemy liczbƒô pr√≥bek 
                        nale≈ºƒÖcych do tych klas dominujƒÖcych i dzielimy przez ca≈ÇkowitƒÖ liczbƒô pr√≥bek.

                        Warto≈õƒá 1.0 oznacza, ≈ºe ka≈ºdy klaster zawiera pr√≥bki tylko z jednej klasy.
                        Ni≈ºsze warto≈õci oznaczajƒÖ, ≈ºe klastry zawierajƒÖ mieszankƒô pr√≥bek z r√≥≈ºnych klas.
                        """)

                # Wizualizacja klastr√≥w na wykresie 2D
                if len(selected_features) >= 2:
                    st.subheader("Wizualizacja klastr√≥w (2D)")

                    # Wyb√≥r cech do wizualizacji
                    viz_col1, viz_col2 = st.columns(2)

                    with viz_col1:
                        feat1 = st.selectbox(
                            "Pierwsza cecha (o≈õ X):",
                            selected_features,
                            index=0,
                            help="Wybierz cechƒô do wy≈õwietlenia na osi X"
                        )

                    with viz_col2:
                        other_feats = [f for f in selected_features if f != feat1]
                        feat2 = st.selectbox(
                            "Druga cecha (o≈õ Y):",
                            other_feats,
                            index=0 if len(other_feats) > 0 else None,
                            help="Wybierz cechƒô do wy≈õwietlenia na osi Y"
                        )

                    # Stw√≥rz wykres
                    fig, ax = plt.subplots(figsize=(10, 8))

                    scatter = ax.scatter(
                        X[feat1],
                        X[feat2],
                        c=cluster_labels,
                        cmap='viridis',
                        alpha=0.8,
                        s=50
                    )

                    # Dodaj centra klastr√≥w dla K-Means
                    if model_code == 'k-means' and 'cluster_centers' in results:
                        centers = np.array(results['cluster_centers'])
                        ax.scatter(
                            centers[:, X.columns.get_loc(feat1)],
                            centers[:, X.columns.get_loc(feat2)],
                            c='red',
                            marker='X',
                            s=200,
                            alpha=1,
                            label='Centra klastr√≥w'
                        )
                        ax.legend()

                    ax.set_xlabel(feat1)
                    ax.set_ylabel(feat2)
                    ax.set_title(f'Wizualizacja klastr√≥w: {feat1} vs {feat2}')
                    ax.grid(True)

                    # Dodaj legendƒô z etykietami klastr√≥w
                    legend = ax.legend(*scatter.legend_elements(), title="Klastry")
                    ax.add_artist(legend)

                    st.pyplot(fig)

                    # Je≈õli dostƒôpne sƒÖ prawdziwe klasy, poka≈º drugi wykres por√≥wnawczy
                    if 'Class' in st.session_state.data.columns and compare_with_true:
                        fig, ax = plt.subplots(figsize=(10, 8))

                        scatter = ax.scatter(
                            X[feat1],
                            X[feat2],
                            c=st.session_state.data['Class'],
                            cmap='plasma',
                            alpha=0.8,
                            s=50
                        )

                        ax.set_xlabel(feat1)
                        ax.set_ylabel(feat2)
                        ax.set_title(f'Prawdziwe klasy: {feat1} vs {feat2}')
                        ax.grid(True)

                        # Dodaj legendƒô z etykietami klas
                        legend = ax.legend(*scatter.legend_elements(), title="Prawdziwe klasy")
                        ax.add_artist(legend)

                        st.pyplot(fig)

                # Podsumowanie wynik√≥w
                st.subheader("Podsumowanie klastrowania")
                show_info_box("Interpretacja wynik√≥w", f"""
                **Model {model_type}** znalaz≈Ç {n_clusters} klastr√≥w w danych.

                **Kluczowe wnioski:**
                1. {"Klastry majƒÖ podobne rozmiary, co sugeruje zr√≥wnowa≈ºonƒÖ strukturƒô danych." if np.std(list(results['cluster_sizes'].values())) / np.mean(list(results['cluster_sizes'].values())) < 0.3 else "Klastry majƒÖ r√≥≈ºne rozmiary, co mo≈ºe wskazywaƒá na naturalne grupowanie danych lub szum."}
                2. {"Wysoki wsp√≥≈Çczynnik silhouette sugeruje dobrze odseparowane klastry." if 'silhouette_score' in results and results['silhouette_score'] > 0.5 else "Umiarkowany wsp√≥≈Çczynnik silhouette sugeruje, ≈ºe klastry czƒô≈õciowo siƒô nak≈ÇadajƒÖ." if 'silhouette_score' in results else ""}

                **Zalecenia:**
                - {"Spr√≥buj zmniejszyƒá liczbƒô klastr√≥w, je≈õli chcesz bardziej og√≥lny podzia≈Ç." if n_clusters > 5 else "Spr√≥buj zwiƒôkszyƒá liczbƒô klastr√≥w, je≈õli chcesz bardziej szczeg√≥≈Çowy podzia≈Ç." if n_clusters < 3 else "Liczba klastr√≥w wydaje siƒô odpowiednia dla tych danych."}
                """)

        elif not selected_features and st.button("Wykonaj klastrowanie", key="no_features"):
            st.error("Wybierz co najmniej jednƒÖ cechƒô do klastrowania.")

    # Regu≈Çy asocjacyjne
    elif model_category == "Regu≈Çy asocjacyjne":
        ml_info = get_ml_model_description("association_rules")
        section_header(ml_info["title"], "Odkrywanie interesujƒÖcych relacji miƒôdzy cechami chemicznymi win")

        with st.expander("‚ÑπÔ∏è O regu≈Çach asocjacyjnych"):
            st.markdown(ml_info["description"])

        # Wyb√≥r cech
        st.subheader("Wyb√≥r cech")

        # Pobierz kolumny numeryczne
        column_types = get_column_types(st.session_state.data)
        numeric_cols = column_types.get('numeric', [])

        # Widget do wyboru cech
        selected_features = st.multiselect(
            "Wybierz cechy do analizy:",
            numeric_cols,
            default=numeric_cols[:8] if len(numeric_cols) > 8 else numeric_cols,
            help="Wybierz cechy, miƒôdzy kt√≥rymi chcesz znale≈∫ƒá relacje"
        )

        # Parametry
        st.subheader("Parametry")

        # Pr√≥g binaryzacji
        threshold = st.slider(
            "Pr√≥g binaryzacji (percentyl):",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="Warto≈õci powy≈ºej tego percentyla bƒôdƒÖ traktowane jako 1, poni≈ºej jako 0"
        )

        # Wsparcie i pewno≈õƒá
        col1, col2 = st.columns(2)

        with col1:
            min_support = st.slider(
                "Minimalne wsparcie:",
                min_value=0.01,
                max_value=0.5,
                value=0.1,
                step=0.01,
                help="Minimalny procent obserwacji zawierajƒÖcych zbi√≥r element√≥w"
            )

        with col2:
            min_confidence = st.slider(
                "Minimalna pewno≈õƒá:",
                min_value=0.5,
                max_value=1.0,
                value=0.7,
                step=0.05,
                help="Minimalna pewno≈õƒá regu≈Çy (wsparcie(X,Y) / wsparcie(X))"
            )

        # Lift i metryka
        col3, col4 = st.columns(2)

        with col3:
            min_lift = st.slider(
                "Minimalny lift:",
                min_value=1.0,
                max_value=5.0,
                value=1.2,
                step=0.1,
                help="Minimalna warto≈õƒá liftu (wsparcie(X,Y) / (wsparcie(X) * wsparcie(Y)))"
            )

        with col4:
            metric = st.selectbox(
                "Metryka do sortowania regu≈Ç:",
                ["confidence", "lift", "leverage", "conviction"],
                index=1,
                help="""
                - Confidence: pewno≈õƒá regu≈Çy
                - Lift: jak bardziej prawdopodobne jest Y przy wystƒÖpieniu X
                - Leverage: r√≥≈ºnica miƒôdzy obserwowanym a oczekiwanym wsparciem
                - Conviction: jak wiele razy regu≈Ça by≈Çaby nieprawdziwa, gdyby X i Y by≈Çy niezale≈ºne
                """
            )

        # Tworzenie i trenowanie modelu
        if st.button("Znajd≈∫ regu≈Çy asocjacyjne", key="train_association_rules") and selected_features:
            # Przygotowanie danych
            X = st.session_state.data[selected_features]

            # Dodaj pasek postƒôpu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Wydobywanie regu≈Ç..."):
                # Aktualizuj pasek postƒôpu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Wydobywanie regu≈Ç asocjacyjnych... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                miner = AssociationRulesMiner()

                # Przygotowanie danych
                miner.prepare_data(X, threshold)

                # Znajd≈∫ czƒôste zbiory element√≥w
                frequent_itemsets = miner.find_frequent_itemsets(min_support)

                # Generuj regu≈Çy
                min_threshold = min_confidence if metric == 'confidence' else min_lift
                rules = miner.generate_rules(min_threshold, metric)

                # Ukryj pasek postƒôpu i tekst statusu po zako≈Ñczeniu
                progress_bar.empty()
                status_text.empty()

                # Wy≈õwietl wyniki
                st.subheader("Czƒôste zbiory element√≥w")

                with st.expander("‚ÑπÔ∏è Co to sƒÖ czƒôste zbiory element√≥w?"):
                    st.markdown("""
                    **Czƒôste zbiory element√≥w** to grupy element√≥w (cech), kt√≥re czƒôsto wystƒôpujƒÖ razem.

                    W kontek≈õcie Wine Dataset, element mo≈ºe oznaczaƒá "cecha X ma wysokƒÖ warto≈õƒá".
                    Na przyk≈Çad, zbi√≥r {Alcohol, Flavanoids} oznacza, ≈ºe wina czƒôsto majƒÖ jednocze≈õnie
                    wysokƒÖ zawarto≈õƒá alkoholu i flawonoid√≥w.

                    Kolumna **support** pokazuje, jaki procent wszystkich win ma jednocze≈õnie wszystkie
                    elementy w danym zbiorze.
                    """)

                if frequent_itemsets is not None and not frequent_itemsets.empty:
                    st.write(f"Znaleziono {len(frequent_itemsets)} czƒôstych zbior√≥w element√≥w.")

                    # Poka≈º najczƒôstsze zbiory
                    st.dataframe(frequent_itemsets.sort_values('support', ascending=False).head(20))
                else:
                    st.info("Nie znaleziono czƒôstych zbior√≥w element√≥w z podanymi parametrami.")

                st.subheader("Regu≈Çy asocjacyjne")

                with st.expander("‚ÑπÔ∏è Jak interpretowaƒá regu≈Çy asocjacyjne?"):
                    st.markdown("""
                    **Regu≈Çy asocjacyjne** majƒÖ format "je≈õli X, to Y" (X ‚Üí Y):

                    - **X** (antecedents) to poprzednik/warunek
                    - **Y** (consequents) to nastƒôpnik/konsekwencja

                    Przyk≈Çad: {wysokie_Alcohol, wysokie_Flavanoids} ‚Üí {wysokie_Proline}

                    Miary jako≈õci regu≈Ç:
                    - **Support**: jaki procent wszystkich pr√≥bek zawiera zar√≥wno X, jak i Y
                    - **Confidence**: jaki procent pr√≥bek zawierajƒÖcych X zawiera r√≥wnie≈º Y
                    - **Lift**: jak wiele razy bardziej prawdopodobne jest Y, gdy wystƒôpuje X

                    Regu≈Çy z wy≈ºszymi warto≈õciami tych miar sƒÖ bardziej interesujƒÖce.
                    """)

                if rules is not None and not rules.empty:
                    st.write(f"Znaleziono {len(rules)} regu≈Ç asocjacyjnych.")

                    # Poka≈º najlepsze regu≈Çy
                    top_rules = miner.get_top_rules(10, metric)
                    st.dataframe(top_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

                    # Sformatowane regu≈Çy
                    st.subheader("Najlepsze regu≈Çy (sformatowane)")
                    formatted_rules = miner.format_rules(top_rules)

                    for i, rule in enumerate(formatted_rules, 1):
                        st.write(f"{i}. {rule}")

                    # Wizualizacja regu≈Ç
                    st.subheader("Wizualizacja regu≈Ç asocjacyjnych")

                    fig, ax = plt.subplots(figsize=(10, 8))

                    # Wybierz regu≈Çy do wizualizacji
                    viz_rules = top_rules.head(15)

                    # Stw√≥rz etykiety dla regu≈Ç
                    rule_labels = [
                        f"{', '.join(list(r['antecedents']))} => {', '.join(list(r['consequents']))}"
                        for _, r in viz_rules.iterrows()
                    ]

                    # Skr√≥ƒá d≈Çugie etykiety
                    rule_labels = [label[:50] + '...' if len(label) > 50 else label for label in rule_labels]

                    # Wykres wsparcia i pewno≈õci
                    scatter = ax.scatter(
                        viz_rules['support'],
                        viz_rules['confidence'],
                        s=viz_rules['lift'] * 100,
                        alpha=0.6
                    )

                    # Dodaj etykiety dla punkt√≥w
                    for i, label in enumerate(rule_labels):
                        ax.annotate(
                            label,
                            (viz_rules['support'].iloc[i], viz_rules['confidence'].iloc[i]),
                            textcoords="offset points",
                            xytext=(0, 10),
                            ha='center',
                            fontsize=8
                        )

                    ax.set_xlabel('Wsparcie (support)')
                    ax.set_ylabel('Pewno≈õƒá (confidence)')
                    ax.set_title('Regu≈Çy asocjacyjne: wsparcie vs pewno≈õƒá (rozmiar = lift)')
                    ax.grid(True)

                    # Dodaj kolorowƒÖ legendƒô dla liftu
                    handles, labels = scatter.legend_elements(
                        prop="sizes",
                        alpha=0.6,
                        func=lambda s: s / 100
                    )
                    ax.legend(handles, labels, title="Lift", loc="upper left")

                    st.pyplot(fig)

                    # Interpretacja wynik√≥w
                    st.subheader("Interpretacja wynik√≥w")
                    show_info_box("Najwa≈ºniejsze wnioski", f"""
                    Z analizy regu≈Ç asocjacyjnych mo≈ºna wyciƒÖgnƒÖƒá nastƒôpujƒÖce wnioski:

                    1. **Najsilniejsze powiƒÖzania** wystƒôpujƒÖ miƒôdzy: {', '.join([f"{','.join(list(r['antecedents']))} => {','.join(list(r['consequents']))}" for _, r in top_rules.head(3).iterrows()])}

                    2. **Najczƒôstsze cechy** wystƒôpujƒÖce w regu≈Çach: {', '.join(set([item for _, row in top_rules.iterrows() for itemset in [row['antecedents'], row['consequents']] for item in itemset]))}

                    3. **Praktyczne zastosowanie**: Regu≈Çy o wysokiej pewno≈õci i lifcie mogƒÖ byƒá u≈ºywane do przewidywania cech chemicznych win na podstawie innych cech.

                    4. **InteresujƒÖce wzorce**: Wina z wysokƒÖ zawarto≈õciƒÖ jednych zwiƒÖzk√≥w czƒôsto majƒÖ r√≥wnie≈º wysokƒÖ zawarto≈õƒá innych zwiƒÖzk√≥w, co mo≈ºe odzwierciedlaƒá procesy biochemiczne zachodzƒÖce podczas produkcji wina.
                    """)
                else:
                    st.info("Nie znaleziono regu≈Ç asocjacyjnych z podanymi parametrami.")

                    # Sugestie
                    st.warning("""
                    **Sugestie:**
                    - Spr√≥buj zmniejszyƒá warto≈õƒá minimalnego wsparcia
                    - Spr√≥buj zmniejszyƒá warto≈õƒá minimalnej pewno≈õci lub liftu
                    - Wybierz wiƒôcej cech do analizy
                    """)

        elif not selected_features and st.button("Znajd≈∫ regu≈Çy asocjacyjne", key="no_features_rules"):
            st.error("Wybierz co najmniej jednƒÖ cechƒô do analizy.")

    # Podsumowanie
    st.markdown("---")
    st.subheader("Por√≥wnanie metod uczenia maszynowego")

    with st.expander("üìö Wskaz√≥wki wyboru odpowiedniej metody"):
        st.markdown("""
        ### Kiedy u≈ºywaƒá r√≥≈ºnych metod uczenia maszynowego:

        **Klasyfikacja:**
        - Gdy masz oznaczone dane (wiesz, do kt√≥rej klasy nale≈ºy ka≈ºda pr√≥bka)
        - Gdy celem jest przewidywanie kategorii dla nowych pr√≥bek
        - Gdy chcesz zrozumieƒá, kt√≥re cechy sƒÖ najwa≈ºniejsze dla rozr√≥≈ºnienia klas

        **Klastrowanie:**
        - Gdy nie masz oznaczonych danych lub chcesz odkryƒá naturalne grupowania
        - Gdy chcesz znale≈∫ƒá ukryte struktury lub segmenty w danych
        - Gdy chcesz zredukowaƒá z≈Ço≈ºono≈õƒá danych, grupujƒÖc podobne pr√≥bki

        **Regu≈Çy asocjacyjne:**
        - Gdy chcesz odkryƒá interesujƒÖce relacje miƒôdzy cechami
        - Gdy szukasz wzorc√≥w wsp√≥≈Çwystƒôpowania cech
        - Gdy chcesz generowaƒá regu≈Çy, kt√≥re mo≈ºna ≈Çatwo interpretowaƒá

        ### Wyb√≥r rodzaju eksperymentu dla klasyfikacji:

        **Train/Test Split:**
        - Szybki i prosty
        - Dobry dla du≈ºych zbior√≥w danych
        - Mo≈ºe byƒá mniej stabilny dla ma≈Çych zbior√≥w

        **Cross-Validation:**
        - Bardziej niezawodny ni≈º train/test split
        - Lepiej wykorzystuje dostƒôpne dane
        - Daje bardziej stabilne oszacowanie wydajno≈õci

        **Leave-One-Out:**
        - Maksymalnie wykorzystuje dane
        - Najlepszy dla bardzo ma≈Çych zbior√≥w danych
        - Mo≈ºe byƒá czasoch≈Çonny dla du≈ºych zbior√≥w
        - Daje najlepsze oszacowanie wydajno≈õci dla ma≈Çych zbior√≥w
        """)

    # Ko≈Ñcowe podsumowanie
    show_info_box("Podsumowanie modelowania uczenia maszynowego", """
    **Najlepsze praktyki modelowania:**

    1. **Wybierz odpowiedni eksperyment**: Dla ma≈Çych zbior√≥w jak Wine Dataset, Cross-Validation lub LOO dajƒÖ bardziej wiarygodne wyniki
    2. **Przygotuj dane odpowiednio**: Skaluj cechy dla wiƒôkszo≈õci modeli, szczeg√≥lnie SVM i KNN
    3. **Wybierz odpowiednie cechy**: Nie wszystkie cechy sƒÖ r√≥wnie wa≈ºne, czasem mniej cech daje lepsze wyniki
    4. **Dostosuj parametry**: Ka≈ºdy model ma parametry, kt√≥re mo≈ºna dostosowaƒá do konkretnego problemu
    5. **Waliduj model**: Zawsze oceniaj model na danych, kt√≥rych nie widzia≈Ç podczas treningu
    6. **Interpretuj wyniki**: Sama dok≈Çadno≈õƒá to nie wszystko, wa≈ºne jest zrozumienie, dlaczego model podejmuje takie decyzje

    Najwa≈ºniejszym elementem jest dopasowanie algorytmu i metody ewaluacji do problemu i danych, kt√≥re masz.
    """)


def display_classification_results(results, experiment_type, model_type):
    """
    Wy≈õwietla wyniki klasyfikacji w zale≈ºno≈õci od typu eksperymentu.

    Args:
        results: S≈Çownik z wynikami
        experiment_type: Typ eksperymentu
        model_type: Typ modelu
    """

    # Nag≈Ç√≥wek wynik√≥w
    st.subheader(f"Wyniki klasyfikacji - {experiment_type}")

    if experiment_type == "Train/Test Split":
        # Tradycyjne wyniki train/test split
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "Dok≈Çadno≈õƒá (zbi√≥r treningowy)",
                f"{results['train_accuracy']:.3f}",
                help="Procent poprawnych przewidywa≈Ñ na danych treningowych"
            )

        with col2:
            st.metric(
                "Dok≈Çadno≈õƒá (zbi√≥r testowy)",
                f"{results['test_accuracy']:.3f}",
                help="Procent poprawnych przewidywa≈Ñ na danych testowych"
            )

        with col3:
            st.metric(
                "Dok≈Çadno≈õƒá (walidacja krzy≈ºowa)",
                f"{results['cross_val_mean']:.3f} ¬± {results['cross_val_std']:.3f}",
                help="≈örednia dok≈Çadno≈õƒá z 5-krotnej walidacji krzy≈ºowej ¬± odchylenie standardowe"
            )

        # Raport klasyfikacji
        st.subheader("Raport klasyfikacji")
        report_df = format_classification_report(results['classification_report'])
        st.dataframe(report_df)

        # Macierz pomy≈Çek
        st.subheader("Macierz pomy≈Çek")
        y_test = results.get('y_test', [])
        if len(y_test) > 0:
            classes = sorted(set(y_test))
            conf_matrix_df = format_confusion_matrix(results['confusion_matrix'], [str(c) for c in classes])
            st.dataframe(conf_matrix_df)

    else:  # Cross-Validation lub Leave-One-Out
        # Wyniki cross-validation
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "≈örednia dok≈Çadno≈õƒá",
                f"{results['cv_mean']:.3f}",
                help="≈örednia dok≈Çadno≈õƒá ze wszystkich fa≈Çd"
            )

        with col2:
            st.metric(
                "Odchylenie standardowe",
                f"{results['cv_std']:.3f}",
                help="Odchylenie standardowe dok≈Çadno≈õci miƒôdzy fa≈Çdami"
            )

        with col3:
            confidence_interval = f"[{results['cv_mean'] - 1.96*results['cv_std']:.3f}, {results['cv_mean'] + 1.96*results['cv_std']:.3f}]"
            st.metric(
                "95% przedzia≈Ç ufno≈õci",
                confidence_interval,
                help="95% przedzia≈Ç ufno≈õci dla dok≈Çadno≈õci"
            )

        # Wyniki dla poszczeg√≥lnych fa≈Çd
        if 'cv_scores' in results:
            st.subheader("Wyniki dla poszczeg√≥lnych fa≈Çd")

            scores_df = pd.DataFrame({
                'Fa≈Çda': range(1, len(results['cv_scores']) + 1),
                'Dok≈Çadno≈õƒá': results['cv_scores']
            })

            st.dataframe(scores_df, use_container_width=True)

            # Wykres dok≈Çadno≈õci dla poszczeg√≥lnych fa≈Çd
            import matplotlib.pyplot as plt
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(scores_df['Fa≈Çda'], scores_df['Dok≈Çadno≈õƒá'], 'o-', linewidth=2, markersize=8)
            ax.axhline(y=results['cv_mean'], color='r', linestyle='--', alpha=0.7, label=f'≈örednia: {results["cv_mean"]:.3f}')
            ax.fill_between(scores_df['Fa≈Çda'],
                           results['cv_mean'] - results['cv_std'],
                           results['cv_mean'] + results['cv_std'],
                           alpha=0.2, color='red', label=f'¬±1 SD')
            ax.set_xlabel('Numer fa≈Çdy')
            ax.set_ylabel('Dok≈Çadno≈õƒá')
            ax.set_title(f'Dok≈Çadno≈õƒá modelu dla poszczeg√≥lnych fa≈Çd ({experiment_type})')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    # Wa≈ºno≈õƒá cech (dla Random Forest)
    if 'feature_importance' in results:
        st.subheader("Wa≈ºno≈õƒá cech")

        # Sortuj cechy wed≈Çug wa≈ºno≈õci
        feature_imp = results['feature_importance']
        sorted_features = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)

        features = [x[0] for x in sorted_features]
        importance = [x[1] for x in sorted_features]

        # Stw√≥rz wykres wa≈ºno≈õci cech
        fig = create_feature_importance(features, importance)
        st.pyplot(fig)

        # Wy≈õwietl tabelƒô z wa≈ºno≈õciƒÖ cech
        importance_df = pd.DataFrame({
            'Cecha': features,
            'Wa≈ºno≈õƒá': importance
        }).sort_values('Wa≈ºno≈õƒá', ascending=False)

        st.dataframe(importance_df)