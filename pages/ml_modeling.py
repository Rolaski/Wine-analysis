"""
ModuÅ‚ odpowiedzialny za stronÄ™ modelowania uczenia maszynowego w aplikacji Wine Dataset Analysis.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time

# Import moduÅ‚Ã³w wÅ‚asnych
from src.ml_modeler import ClassificationModel, ClusteringModel, AssociationRulesMiner
from src.data_loader import split_features_target
from src.utils import (
    format_classification_report, format_confusion_matrix,
    generate_model_parameter_description, get_column_types
)
from src.data_visualizer import create_feature_importance
from components.descriptions import (
    get_page_description, get_ml_model_description,
    get_model_parameter_description
)
from components.ui_helpers import show_info_box, section_header


def page_ml_modeling():
    """WyÅ›wietla stronÄ™ modelowania uczenia maszynowego."""

    # Pobierz opis strony
    page_info = get_page_description("ml_modeling")

    # NagÅ‚Ã³wek strony
    st.header(page_info["title"])
    st.markdown(page_info["description"])

    # Wprowadzenie do uczenia maszynowego
    with st.expander("â„¹ï¸ O uczeniu maszynowym na danych Wine Dataset", expanded=True):
        st.markdown("""
        **Uczenie maszynowe** to technika analizy danych, ktÃ³ra umoÅ¼liwia systemom automatyczne uczenie siÄ™ i poprawianie
        na podstawie doÅ›wiadczenia bez jawnego programowania.

        W kontekÅ›cie zbioru danych Wine Dataset moÅ¼emy zastosowaÄ‡ rÃ³Å¼ne techniki uczenia maszynowego:

        - **Klasyfikacja**: Przewidywanie klasy wina (1, 2 lub 3) na podstawie jego cech chemicznych
        - **Klastrowanie**: Grupowanie podobnych win bez wczeÅ›niejszej wiedzy o ich klasach
        - **ReguÅ‚y asocjacyjne**: Odkrywanie interesujÄ…cych relacji miÄ™dzy cechami chemicznymi win

        ZbiÃ³r danych Wine jest idealny do eksperymentowania z uczeniem maszynowym, poniewaÅ¼:
        - Jest stosunkowo maÅ‚y (178 prÃ³bek), co umoÅ¼liwia szybkie trenowanie modeli
        - Zawiera 13 cech, co jest wystarczajÄ…co zÅ‚oÅ¼one, ale nie przytÅ‚aczajÄ…ce
        - Klasy sÄ… doÅ›Ä‡ dobrze rozdzielone, co pozwala uzyskaÄ‡ wysokÄ… dokÅ‚adnoÅ›Ä‡

        W tej sekcji moÅ¼esz trenowaÄ‡ i ewaluowaÄ‡ rÃ³Å¼ne modele uczenia maszynowego na zbiorze danych Wine.
        """)

    # WybÃ³r kategorii modelu
    st.markdown("---")
    st.subheader("Wybierz typ modelowania")

    model_category = st.selectbox(
        "Kategoria modelu:",
        ["Klasyfikacja", "Klastrowanie", "ReguÅ‚y asocjacyjne"],
        help="Wybierz typ modelowania uczenia maszynowego do zastosowania"
    )

    # Klasyfikacja
    if model_category == "Klasyfikacja":
        ml_info = get_ml_model_description("classification")
        section_header(ml_info["title"], "Przewidywanie klasy wina na podstawie cech chemicznych")

        with st.expander("â„¹ï¸ O modelach klasyfikacyjnych"):
            st.markdown(ml_info["description"])

        # SprawdÅº, czy kolumna Class istnieje
        if 'Class' not in st.session_state.data.columns:
            st.error("Kolumna 'Class' nie istnieje w danych. Nie moÅ¼na wykonaÄ‡ klasyfikacji.")
            return

        # WybÃ³r modelu klasyfikacji
        model_type = st.selectbox(
            "Wybierz model klasyfikacji:",
            ["Random Forest (rf)", "K-Nearest Neighbors (knn)", "Support Vector Machine (svm)"],
            index=0,
            help="Wybierz algorytm klasyfikacji do zastosowania"
        )

        # Mapowanie wyÅ›wietlanej nazwy na kod
        model_code = model_type.split(' ')[0].lower()
        if model_code == "random":
            model_code = "rf"
        elif model_code == "k-nearest":
            model_code = "knn"
        elif model_code == "support":
            model_code = "svm"

        # Parametry modelu
        st.subheader("Parametry modelu")

        with st.expander("â„¹ï¸ Co to sÄ… parametry modelu?"):
            st.markdown("""
            **Parametry modelu** (hiperparametry) to wartoÅ›ci konfiguracyjne, ktÃ³re kontrolujÄ… zachowanie 
            algorytmu uczenia maszynowego. WÅ‚aÅ›ciwy dobÃ³r parametrÃ³w moÅ¼e znacznie poprawiÄ‡ wydajnoÅ›Ä‡ modelu.

            KaÅ¼dy model ma inne parametry, ktÃ³re wpÅ‚ywajÄ… na rÃ³Å¼ne aspekty jego dziaÅ‚ania:
            - Jak zÅ‚oÅ¼ony jest model
            - Jak szybko siÄ™ uczy
            - Jak dobrze generalizuje na nowe dane

            Dostosowanie tych parametrÃ³w do konkretnego problemu i danych nazywa siÄ™ **strojeniem hiperparametrÃ³w**.
            """)

        # Pobierz opisy parametrÃ³w dla wybranego modelu
        param_desc = generate_model_parameter_description(model_code)
        params = {}

        # Dynamicznie generuj widgety dla parametrÃ³w modelu
        for param_name, param_info in param_desc.items():
            # Dodaj opis parametru
            st.markdown(f"**{param_info['name']}**")
            help_text = get_model_parameter_description(model_code, param_name)

            # Wybierz odpowiedni typ widgetu
            if 'options' in param_info:
                params[param_name] = st.selectbox(
                    f"Wybierz wartoÅ›Ä‡ dla {param_info['name']}:",
                    param_info['options'],
                    index=param_info['options'].index(param_info['default']) if param_info['default'] in param_info[
                        'options'] else 0,
                    help=help_text
                )
            elif 'min' in param_info and 'max' in param_info:
                step = param_info.get('step', 1)
                params[param_name] = st.slider(
                    f"Ustaw wartoÅ›Ä‡ dla {param_info['name']}:",
                    param_info['min'],
                    param_info['max'],
                    param_info['default'],
                    step=step,
                    help=help_text
                )

        # Przygotowanie danych
        st.subheader("Przygotowanie danych")

        # WybÃ³r proporcji podziaÅ‚u danych
        test_size = st.slider(
            "Proporcja zbioru testowego:",
            min_value=0.1,
            max_value=0.5,
            value=0.2,
            step=0.05,
            help="Jaka czÄ™Å›Ä‡ danych zostanie uÅ¼yta do testowania (reszta do treningu)"
        )

        # Opcja skalowania danych
        scale_data = st.checkbox(
            "Skaluj dane przed trenowaniem",
            value=True,
            help="Zalecane dla wiÄ™kszoÅ›ci modeli, szczegÃ³lnie SVM i KNN"
        )

        # Tworzenie i trening modelu
        if st.button("Trenuj model", key="train_classification"):
            # Przygotowanie danych
            X, y = split_features_target(st.session_state.data)

            # Dodaj pasek postÄ™pu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Trening modelu..."):
                # Aktualizuj pasek postÄ™pu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Trening modelu {model_type}... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                model = ClassificationModel(model_code)

                # Przygotowanie danych
                model.prepare_data(X, y, test_size=test_size)

                # Trening modelu
                results = model.train(params)

                # Ukryj pasek postÄ™pu i tekst statusu po zakoÅ„czeniu
                progress_bar.empty()
                status_text.empty()

                # WyÅ›wietl komunikat o sukcesie
                st.success(f"Model {model_type} zostaÅ‚ pomyÅ›lnie wytrenowany!")

                # NagÅ‚Ã³wek wynikÃ³w
                st.subheader("Wyniki klasyfikacji")

                # Metryki dokÅ‚adnoÅ›ci
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        "DokÅ‚adnoÅ›Ä‡ (zbiÃ³r treningowy)",
                        f"{results['train_accuracy']:.3f}",
                        help="Procent poprawnych przewidywaÅ„ na danych treningowych"
                    )

                with col2:
                    st.metric(
                        "DokÅ‚adnoÅ›Ä‡ (zbiÃ³r testowy)",
                        f"{results['test_accuracy']:.3f}",
                        help="Procent poprawnych przewidywaÅ„ na danych testowych"
                    )

                with col3:
                    st.metric(
                        "DokÅ‚adnoÅ›Ä‡ (walidacja krzyÅ¼owa)",
                        f"{results['cross_val_mean']:.3f} Â± {results['cross_val_std']:.3f}",
                        help="Åšrednia dokÅ‚adnoÅ›Ä‡ z 5-krotnej walidacji krzyÅ¼owej Â± odchylenie standardowe"
                    )

                # Raport klasyfikacji
                st.subheader("Raport klasyfikacji")

                with st.expander("â„¹ï¸ Jak interpretowaÄ‡ raport klasyfikacji?"):
                    st.markdown("""
                    **Raport klasyfikacji** zawiera szczegÃ³Å‚owe metryki dla kaÅ¼dej klasy:

                    - **Precision (precyzja)**: Ile z przewidzianych pozytywnych wynikÃ³w byÅ‚o rzeczywiÅ›cie pozytywnych
                    - **Recall (czuÅ‚oÅ›Ä‡)**: Ile rzeczywiÅ›cie pozytywnych wynikÃ³w zostaÅ‚o poprawnie przewidzianych
                    - **F1-score**: Åšrednia harmoniczna precision i recall, dobra miara ogÃ³lnej wydajnoÅ›ci
                    - **Support**: Liczba wystÄ…pieÅ„ kaÅ¼dej klasy w zbiorze testowym

                    Im wyÅ¼sze wartoÅ›ci precision, recall i F1, tym lepszy model.
                    """)

                report_df = format_classification_report(results['classification_report'])
                st.dataframe(report_df)

                # Macierz pomyÅ‚ek
                st.subheader("Macierz pomyÅ‚ek")

                with st.expander("â„¹ï¸ Jak interpretowaÄ‡ macierz pomyÅ‚ek?"):
                    st.markdown("""
                    **Macierz pomyÅ‚ek** pokazuje, ile prÃ³bek z kaÅ¼dej prawdziwej klasy zostaÅ‚o przypisanych do kaÅ¼dej przewidywanej klasy:

                    - KomÃ³rki na **przekÄ…tnej** pokazujÄ… poprawne przewidywania
                    - KomÃ³rki **poza przekÄ…tnÄ…** pokazujÄ… bÅ‚Ä™dne przewidywania

                    Idealna macierz pomyÅ‚ek ma wysokie wartoÅ›ci na przekÄ…tnej i zera poza niÄ….
                    """)

                classes = sorted(y.unique())
                conf_matrix_df = format_confusion_matrix(results['confusion_matrix'], [str(c) for c in classes])
                st.dataframe(conf_matrix_df)

                # Wizualizacja macierzy pomyÅ‚ek
                fig, ax = plt.subplots(figsize=(8, 6))
                conf_matrix = np.array(results['confusion_matrix'])

                sns_heatmap = None
                try:
                    import seaborn as sns
                    sns_heatmap = sns.heatmap(
                        conf_matrix,
                        annot=True,
                        fmt='d',
                        cmap='Blues',
                        xticklabels=[f'Klasa {c}' for c in classes],
                        yticklabels=[f'Klasa {c}' for c in classes],
                        ax=ax
                    )
                except:
                    # Fallback jeÅ›li seaborn nie jest dostÄ™pny
                    im = ax.imshow(conf_matrix, cmap='Blues')
                    for i in range(len(classes)):
                        for j in range(len(classes)):
                            ax.text(j, i, conf_matrix[i, j], ha='center', va='center')

                ax.set_xlabel('Przewidywana klasa')
                ax.set_ylabel('Prawdziwa klasa')
                ax.set_title('Macierz pomyÅ‚ek')

                st.pyplot(fig)

                # WaÅ¼noÅ›Ä‡ cech (tylko dla Random Forest)
                if 'feature_importance' in results:
                    st.subheader("WaÅ¼noÅ›Ä‡ cech")

                    with st.expander("â„¹ï¸ Co to jest waÅ¼noÅ›Ä‡ cech?"):
                        st.markdown("""
                        **WaÅ¼noÅ›Ä‡ cech** pokazuje, ktÃ³re cechy miaÅ‚y najwiÄ™kszy wpÅ‚yw na decyzje modelu.

                        W przypadku **Random Forest**, waÅ¼noÅ›Ä‡ cechy jest obliczana na podstawie tego,
                        o ile pogarsza siÄ™ wydajnoÅ›Ä‡ modelu, gdy wartoÅ›ci tej cechy sÄ… losowo mieszane.

                        Cechy z wyÅ¼szymi wartoÅ›ciami waÅ¼noÅ›ci majÄ… wiÄ™kszy wpÅ‚yw na przewidywania modelu.
                        """)

                    # Sortuj cechy wedÅ‚ug waÅ¼noÅ›ci
                    feature_imp = results['feature_importance']
                    sorted_features = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)

                    features = [x[0] for x in sorted_features]
                    importance = [x[1] for x in sorted_features]

                    # StwÃ³rz wykres waÅ¼noÅ›ci cech
                    fig = create_feature_importance(features, importance)
                    st.pyplot(fig)

                    # WyÅ›wietl tabelÄ™ z waÅ¼noÅ›ciÄ… cech
                    importance_df = pd.DataFrame({
                        'Cecha': features,
                        'WaÅ¼noÅ›Ä‡': importance
                    }).sort_values('WaÅ¼noÅ›Ä‡', ascending=False)

                    st.dataframe(importance_df)

                    # Podsumowanie wynikÃ³w
                    st.subheader("Podsumowanie wynikÃ³w")
                    show_info_box("Interpretacja wynikÃ³w", f"""
                **Kluczowe wnioski:**
                1. Model ma wysokÄ… dokÅ‚adnoÅ›Ä‡ (>0.9), co sugeruje dobry fit do danych.
                2. RÃ³Å¼nica miÄ™dzy dokÅ‚adnoÅ›ciÄ… treningowÄ… a testowÄ… jest niewielka, co sugeruje dobry poziom generalizacji.
                3. Wszystkie klasy sÄ… podobnie dobrze klasyfikowane.

                **Zalecenia:**
                - MoÅ¼na uznaÄ‡ model za zadowalajÄ…cy i gotowy do uÅ¼ycia.
                - Cechy o najwyÅ¼szej waÅ¼noÅ›ci mogÄ… byÄ‡ kluczowe dla przewidywania klasy wina.
                """)

    # Klastrowanie
    elif model_category == "Klastrowanie":
        ml_info = get_ml_model_description("clustering")
        section_header(ml_info["title"], "Grupowanie win o podobnych cechach chemicznych")

        with st.expander("â„¹ï¸ O modelach klastrowania"):
            st.markdown(ml_info["description"])

        # WybÃ³r modelu klastrowania
        model_type = st.selectbox(
            "Wybierz model klastrowania:",
            ["K-Means", "DBSCAN"],
            index=0,
            help="Wybierz algorytm klastrowania do zastosowania"
        )

        # Mapowanie wyÅ›wietlanej nazwy na kod
        model_code = model_type.lower()

        # Parametry modelu
        st.subheader("Parametry modelu")

        # Pobierz opisy parametrÃ³w dla wybranego modelu
        param_desc = generate_model_parameter_description(model_code)
        params = {}

        # Dynamicznie generuj widgety dla parametrÃ³w modelu
        for param_name, param_info in param_desc.items():
            # Dodaj opis parametru
            st.markdown(f"**{param_info['name']}**")
            help_text = get_model_parameter_description(model_code, param_name)

            # Wybierz odpowiedni typ widgetu
            if 'options' in param_info:
                params[param_name] = st.selectbox(
                    f"Wybierz wartoÅ›Ä‡ dla {param_info['name']}:",
                    param_info['options'],
                    index=param_info['options'].index(param_info['default']) if param_info['default'] in param_info[
                        'options'] else 0,
                    help=help_text
                )
            elif 'min' in param_info and 'max' in param_info:
                step = param_info.get('step', 1)
                params[param_name] = st.slider(
                    f"Ustaw wartoÅ›Ä‡ dla {param_info['name']}:",
                    param_info['min'],
                    param_info['max'],
                    param_info['default'],
                    step=step,
                    help=help_text
                )

        # WybÃ³r cech do klastrowania
        st.subheader("WybÃ³r cech")

        # Pobierz kolumny numeryczne
        column_types = get_column_types(st.session_state.data)
        numeric_cols = column_types.get('numeric', [])

        # UsuÅ„ kolumnÄ™ Class z listy, jeÅ›li istnieje
        if 'Class' in numeric_cols:
            numeric_cols.remove('Class')

        # Widget do wyboru cech
        selected_features = st.multiselect(
            "Wybierz cechy do klastrowania:",
            numeric_cols,
            default=numeric_cols[:5] if len(numeric_cols) > 5 else numeric_cols,
            help="Wybierz cechy, na podstawie ktÃ³rych bÄ™dÄ… grupowane wina"
        )

        # Opcja porÃ³wnania z prawdziwymi klasami
        compare_with_true = st.checkbox(
            "PorÃ³wnaj z prawdziwymi klasami",
            value=True,
            help="PorÃ³wnaj znalezione klastry z prawdziwymi klasami win (jeÅ›li dostÄ™pne)"
        )

        # Przycisk do trenowania modelu
        if st.button("Wykonaj klastrowanie", key="train_clustering") and selected_features:
            # Przygotowanie danych
            X = st.session_state.data[selected_features]

            # Dodaj pasek postÄ™pu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Klastrowanie danych..."):
                # Aktualizuj pasek postÄ™pu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Wykonywanie klastrowania {model_type}... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                model = ClusteringModel(model_code)

                # Przygotowanie danych
                model.prepare_data(X)

                # Znajdowanie optymalnej liczby klastrÃ³w dla K-Means
                if model_code == 'kmeans':
                    st.subheader("Znajdowanie optymalnej liczby klastrÃ³w")
                    max_clusters = st.slider(
                        "Maksymalna liczba klastrÃ³w do sprawdzenia:",
                        min_value=2,
                        max_value=15,
                        value=10,
                        help="WiÄ™ksza liczba = dÅ‚uÅ¼szy czas obliczeÅ„"
                    )

                    with st.spinner("Szukanie optymalnej liczby klastrÃ³w..."):
                        optimal_results = model.find_optimal_clusters(max_clusters)

                        # Wykres metody Å‚okcia (inertia)
                        st.subheader("Metoda Å‚okcia (inertia)")

                        with st.expander("â„¹ï¸ Jak interpretowaÄ‡ metodÄ™ Å‚okcia?"):
                            st.markdown("""
                            **Metoda Å‚okcia** pomaga znaleÅºÄ‡ optymalnÄ… liczbÄ™ klastrÃ³w poprzez wykres inercji
                            (sumy kwadratÃ³w odlegÅ‚oÅ›ci punktÃ³w od ich centroidÃ³w) w zaleÅ¼noÅ›ci od liczby klastrÃ³w.

                            Szukamy "Å‚okcia" na wykresie - punktu, w ktÃ³rym dodanie kolejnego klastra daje 
                            znacznie mniejszy spadek inercji. Ten punkt sugeruje optymalnÄ… liczbÄ™ klastrÃ³w.
                            """)

                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.plot(optimal_results["k_values"], optimal_results["inertias"], 'o-')
                        ax.set_xlabel('Liczba klastrÃ³w (k)')
                        ax.set_ylabel('Inertia')
                        ax.set_title('Metoda Å‚okcia dla okreÅ›lenia optymalnej liczby klastrÃ³w')
                        ax.grid(True)
                        st.pyplot(fig)

                        # Wykres wspÃ³Å‚czynnika silhouette
                        st.subheader("WspÃ³Å‚czynnik silhouette")

                        with st.expander("â„¹ï¸ Jak interpretowaÄ‡ wspÃ³Å‚czynnik silhouette?"):
                            st.markdown("""
                            **WspÃ³Å‚czynnik silhouette** mierzy, jak podobny jest obiekt do wÅ‚asnego klastra
                            w porÃ³wnaniu do innych klastrÃ³w. WartoÅ›ci wahajÄ… siÄ™ od -1 do 1:

                            - **WartoÅ›ci bliskie 1**: Obiekt jest dobrze przypisany do swojego klastra
                            - **WartoÅ›ci bliskie 0**: Obiekt jest na granicy miÄ™dzy klastrami
                            - **WartoÅ›ci bliskie -1**: Obiekt prawdopodobnie jest w zÅ‚ym klastrze

                            WyÅ¼sze wartoÅ›ci Å›rednie wskazujÄ… lepszÄ… konfiguracjÄ™ klastrÃ³w.
                            """)

                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.plot(optimal_results["k_values"], optimal_results["silhouettes"], 'o-')
                        ax.set_xlabel('Liczba klastrÃ³w (k)')
                        ax.set_ylabel('WspÃ³Å‚czynnik silhouette')
                        ax.set_title('WspÃ³Å‚czynnik silhouette dla okreÅ›lenia optymalnej liczby klastrÃ³w')
                        ax.grid(True)
                        st.pyplot(fig)

                        # Informacja o optymalnej liczbie klastrÃ³w
                        st.info(
                            f"Optymalna liczba klastrÃ³w na podstawie wspÃ³Å‚czynnika silhouette: {optimal_results['optimal_k']}")

                        # Aktualizacja liczby klastrÃ³w
                        params['n_clusters'] = optimal_results['optimal_k']

                # Trening modelu
                results = model.train(params)

                # Ukryj pasek postÄ™pu i tekst statusu po zakoÅ„czeniu
                progress_bar.empty()
                status_text.empty()

                # WyÅ›wietl komunikat o sukcesie
                st.success(f"Klastrowanie {model_type} zostaÅ‚o pomyÅ›lnie wykonane!")

                # Dodaj etykiety klastrÃ³w do danych
                cluster_labels = model.get_clusters()
                clustering_result = X.copy()
                clustering_result['Klaster'] = cluster_labels

                # JeÅ›li istnieje kolumna Class, dodaj jÄ… do wynikÃ³w
                if 'Class' in st.session_state.data.columns and compare_with_true:
                    clustering_result['Prawdziwa_klasa'] = st.session_state.data['Class']

                # WyÅ›wietlenie wynikÃ³w
                st.subheader("Wyniki klastrowania")

                # Podstawowe informacje
                n_clusters = results['n_clusters']
                st.write(f"Liczba klastrÃ³w: {n_clusters}")

                # Liczba prÃ³bek w kaÅ¼dym klastrze
                st.subheader("RozkÅ‚ad klastrÃ³w")
                cluster_sizes = pd.DataFrame.from_dict(
                    results['cluster_sizes'],
                    orient='index',
                    columns=['Liczba prÃ³bek']
                )
                cluster_sizes.index.name = 'Klaster'
                st.dataframe(cluster_sizes)

                # Wykres rozkÅ‚adu klastrÃ³w
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.bar(cluster_sizes.index.astype(str), cluster_sizes['Liczba prÃ³bek'])
                ax.set_xlabel('Klaster')
                ax.set_ylabel('Liczba prÃ³bek')
                ax.set_title('RozkÅ‚ad prÃ³bek w klastrach')
                ax.grid(axis='y')
                st.pyplot(fig)

                # Dodatkowe informacje dla K-Means
                if model_code == 'kmeans':
                    st.subheader("Inertia")
                    st.write(f"Inertia: {results['inertia']:.3f}")

                    with st.expander("â„¹ï¸ Co to jest inertia?"):
                        st.markdown("""
                        **Inertia** to suma kwadratÃ³w odlegÅ‚oÅ›ci kaÅ¼dej prÃ³bki od centroidu jej klastra.

                        Mniejsza wartoÅ›Ä‡ inertia oznacza, Å¼e punkty sÄ… bliÅ¼ej swoich centroidÃ³w,
                        co sugeruje lepszy podziaÅ‚ klastrÃ³w.
                        """)

                # WspÃ³Å‚czynnik silhouette (jeÅ›li dostÄ™pny)
                if 'silhouette_score' in results:
                    st.subheader("WspÃ³Å‚czynnik silhouette")

                    score = results['silhouette_score']
                    st.write(f"WspÃ³Å‚czynnik silhouette: {score:.3f}")

                    # Interpretacja wyniku
                    if score > 0.7:
                        st.success("Silna struktura klastrÃ³w.")
                    elif score > 0.5:
                        st.info("Åšrednia struktura klastrÃ³w.")
                    elif score > 0.25:
                        st.warning("SÅ‚aba struktura klastrÃ³w.")
                    else:
                        st.error("Brak znaczÄ…cej struktury klastrÃ³w.")

                # PorÃ³wnanie z prawdziwymi klasami (jeÅ›li dostÄ™pne)
                if 'Class' in st.session_state.data.columns and compare_with_true:
                    st.subheader("PorÃ³wnanie z prawdziwymi klasami")

                    # Tabela pokazujÄ…ca liczbÄ™ win z kaÅ¼dej klasy w kaÅ¼dym klastrze
                    cross_tab = pd.crosstab(
                        clustering_result['Klaster'],
                        clustering_result['Prawdziwa_klasa'],
                        rownames=['Klaster'],
                        colnames=['Prawdziwa klasa']
                    )

                    st.dataframe(cross_tab)

                    # Wizualizacja porÃ³wnania
                    fig, ax = plt.subplots(figsize=(10, 6))
                    cross_tab.plot(kind='bar', stacked=True, ax=ax)
                    ax.set_xlabel('Klaster')
                    ax.set_ylabel('Liczba prÃ³bek')
                    ax.set_title('RozkÅ‚ad prawdziwych klas w klastrach')
                    ax.legend(title='Prawdziwa klasa')
                    st.pyplot(fig)

                    # Obliczanie czystoÅ›ci klastrÃ³w
                    cluster_purity = np.sum([np.max(cross_tab.values[i]) for i in range(len(cross_tab))]) / np.sum(
                        cross_tab.values)
                    st.metric(
                        "CzystoÅ›Ä‡ klastrÃ³w",
                        f"{cluster_purity:.3f}",
                        help="Procent prÃ³bek w kaÅ¼dym klastrze naleÅ¼Ä…cych do klasy najczÄ™Å›ciej wystÄ™pujÄ…cej w tym klastrze"
                    )

                    with st.expander("â„¹ï¸ Co to jest czystoÅ›Ä‡ klastrÃ³w?"):
                        st.markdown("""
                        **CzystoÅ›Ä‡ klastrÃ³w** (cluster purity) to miara, ktÃ³ra pokazuje, jak dobrze klastry odpowiadajÄ… prawdziwym klasom.

                        Dla kaÅ¼dego klastra znajdujemy klasÄ™, ktÃ³ra wystÄ™puje w nim najczÄ™Å›ciej. NastÄ™pnie sumujemy liczbÄ™ prÃ³bek 
                        naleÅ¼Ä…cych do tych klas dominujÄ…cych i dzielimy przez caÅ‚kowitÄ… liczbÄ™ prÃ³bek.

                        WartoÅ›Ä‡ 1.0 oznacza, Å¼e kaÅ¼dy klaster zawiera prÃ³bki tylko z jednej klasy.
                        NiÅ¼sze wartoÅ›ci oznaczajÄ…, Å¼e klastry zawierajÄ… mieszankÄ™ prÃ³bek z rÃ³Å¼nych klas.
                        """)

                # Wizualizacja klastrÃ³w na wykresie 2D
                if len(selected_features) >= 2:
                    st.subheader("Wizualizacja klastrÃ³w (2D)")

                    # WybÃ³r cech do wizualizacji
                    viz_col1, viz_col2 = st.columns(2)

                    with viz_col1:
                        feat1 = st.selectbox(
                            "Pierwsza cecha (oÅ› X):",
                            selected_features,
                            index=0,
                            help="Wybierz cechÄ™ do wyÅ›wietlenia na osi X"
                        )

                    with viz_col2:
                        other_feats = [f for f in selected_features if f != feat1]
                        feat2 = st.selectbox(
                            "Druga cecha (oÅ› Y):",
                            other_feats,
                            index=0 if len(other_feats) > 0 else None,
                            help="Wybierz cechÄ™ do wyÅ›wietlenia na osi Y"
                        )

                    # StwÃ³rz wykres
                    fig, ax = plt.subplots(figsize=(10, 8))

                    scatter = ax.scatter(
                        X[feat1],
                        X[feat2],
                        c=cluster_labels,
                        cmap='viridis',
                        alpha=0.8,
                        s=50
                    )

                    # Dodaj centra klastrÃ³w dla K-Means
                    if model_code == 'kmeans' and 'cluster_centers' in results:
                        centers = np.array(results['cluster_centers'])
                        ax.scatter(
                            centers[:, X.columns.get_loc(feat1)],
                            centers[:, X.columns.get_loc(feat2)],
                            c='red',
                            marker='X',
                            s=200,
                            alpha=1,
                            label='Centra klastrÃ³w'
                        )
                        ax.legend()

                    ax.set_xlabel(feat1)
                    ax.set_ylabel(feat2)
                    ax.set_title(f'Wizualizacja klastrÃ³w: {feat1} vs {feat2}')
                    ax.grid(True)

                    # Dodaj legendÄ™ z etykietami klastrÃ³w
                    legend = ax.legend(*scatter.legend_elements(), title="Klastry")
                    ax.add_artist(legend)

                    st.pyplot(fig)

                    # JeÅ›li dostÄ™pne sÄ… prawdziwe klasy, pokaÅ¼ drugi wykres porÃ³wnawczy
                    if 'Class' in st.session_state.data.columns and compare_with_true:
                        fig, ax = plt.subplots(figsize=(10, 8))

                        scatter = ax.scatter(
                            X[feat1],
                            X[feat2],
                            c=st.session_state.data['Class'],
                            cmap='plasma',
                            alpha=0.8,
                            s=50
                        )

                        ax.set_xlabel(feat1)
                        ax.set_ylabel(feat2)
                        ax.set_title(f'Prawdziwe klasy: {feat1} vs {feat2}')
                        ax.grid(True)

                        # Dodaj legendÄ™ z etykietami klas
                        legend = ax.legend(*scatter.legend_elements(), title="Prawdziwe klasy")
                        ax.add_artist(legend)

                        st.pyplot(fig)

                # Wizualizacja klastrÃ³w na wykresie 3D (jeÅ›li dostÄ™pne sÄ… co najmniej 3 cechy)
                if len(selected_features) >= 3:
                    st.subheader("Wizualizacja klastrÃ³w (3D)")

                    # WybÃ³r cech do wizualizacji
                    viz_col1, viz_col2, viz_col3 = st.columns(3)

                    with viz_col1:
                        feat1_3d = st.selectbox(
                            "Pierwsza cecha (oÅ› X):",
                            selected_features,
                            index=0,
                            key="feat1_3d",
                            help="Wybierz cechÄ™ do wyÅ›wietlenia na osi X"
                        )

                    with viz_col2:
                        other_feats_3d = [f for f in selected_features if f != feat1_3d]
                        feat2_3d = st.selectbox(
                            "Druga cecha (oÅ› Y):",
                            other_feats_3d,
                            index=0 if len(other_feats_3d) > 0 else None,
                            key="feat2_3d",
                            help="Wybierz cechÄ™ do wyÅ›wietlenia na osi Y"
                        )

                    with viz_col3:
                        other_feats_3d_2 = [f for f in selected_features if f != feat1_3d and f != feat2_3d]
                        feat3_3d = st.selectbox(
                            "Trzecia cecha (oÅ› Z):",
                            other_feats_3d_2,
                            index=0 if len(other_feats_3d_2) > 0 else None,
                            key="feat3_3d",
                            help="Wybierz cechÄ™ do wyÅ›wietlenia na osi Z"
                        )

                    # Informacja o interaktywnoÅ›ci
                    st.info("ğŸ’¡ WskazÃ³wka: MoÅ¼esz obrÃ³ciÄ‡ wykres 3D, klikajÄ…c i przeciÄ…gajÄ…c go myszÄ….")

                    # StwÃ³rz wykres 3D
                    fig = plt.figure(figsize=(10, 8))
                    ax = fig.add_subplot(111, projection='3d')

                    scatter = ax.scatter(
                        X[feat1_3d],
                        X[feat2_3d],
                        X[feat3_3d],
                        c=cluster_labels,
                        cmap='viridis',
                        alpha=0.8,
                        s=50
                    )

                    # Dodaj centra klastrÃ³w dla K-Means w 3D
                    if model_code == 'kmeans' and 'cluster_centers' in results:
                        centers = np.array(results['cluster_centers'])
                        ax.scatter(
                            centers[:, X.columns.get_loc(feat1_3d)],
                            centers[:, X.columns.get_loc(feat2_3d)],
                            centers[:, X.columns.get_loc(feat3_3d)],
                            c='red',
                            marker='X',
                            s=200,
                            alpha=1,
                            label='Centra klastrÃ³w'
                        )
                        ax.legend()

                    ax.set_xlabel(feat1_3d)
                    ax.set_ylabel(feat2_3d)
                    ax.set_zlabel(feat3_3d)
                    ax.set_title(f'Wizualizacja klastrÃ³w 3D: {feat1_3d} vs {feat2_3d} vs {feat3_3d}')

                    # Dodaj legendÄ™ z etykietami klastrÃ³w
                    legend = ax.legend(*scatter.legend_elements(), title="Klastry")
                    ax.add_artist(legend)

                    st.pyplot(fig)

                # Podsumowanie wynikÃ³w
                st.subheader("Podsumowanie klastrowania")
                show_info_box("Interpretacja wynikÃ³w", f"""
                **Model {model_type}** znalazÅ‚ {n_clusters} klastrÃ³w w danych.

                **Kluczowe wnioski:**
                1. {"Klastry majÄ… podobne rozmiary, co sugeruje zrÃ³wnowaÅ¼onÄ… strukturÄ™ danych." if np.std(list(results['cluster_sizes'].values())) / np.mean(list(results['cluster_sizes'].values())) < 0.3 else "Klastry majÄ… rÃ³Å¼ne rozmiary, co moÅ¼e wskazywaÄ‡ na naturalne grupowanie danych lub szum."}
                2. {"Wysoki wspÃ³Å‚czynnik silhouette sugeruje dobrze odseparowane klastry." if 'silhouette_score' in results and results['silhouette_score'] > 0.5 else "Umiarkowany wspÃ³Å‚czynnik silhouette sugeruje, Å¼e klastry czÄ™Å›ciowo siÄ™ nakÅ‚adajÄ…." if 'silhouette_score' in results else ""}
                3. {"Klastry dobrze odpowiadajÄ… prawdziwym klasom (wysoka czystoÅ›Ä‡ klastrÃ³w)." if 'Class' in st.session_state.data.columns and compare_with_true and cluster_purity > 0.7 else "Klastry tylko czÄ™Å›ciowo odpowiadajÄ… prawdziwym klasom." if 'Class' in st.session_state.data.columns and compare_with_true else ""}

                **Zalecenia:**
                - {"SprÃ³buj zmniejszyÄ‡ liczbÄ™ klastrÃ³w, jeÅ›li chcesz bardziej ogÃ³lny podziaÅ‚." if n_clusters > 5 else "SprÃ³buj zwiÄ™kszyÄ‡ liczbÄ™ klastrÃ³w, jeÅ›li chcesz bardziej szczegÃ³Å‚owy podziaÅ‚." if n_clusters < 3 else "Liczba klastrÃ³w wydaje siÄ™ odpowiednia dla tych danych."}
                - {"WyprÃ³buj inne kombinacje cech, aby zobaczyÄ‡, czy poprawiÄ… one separacjÄ™ klastrÃ³w." if 'silhouette_score' in results and results['silhouette_score'] < 0.5 else ""}
                """)

        elif not selected_features and st.button("Wykonaj klastrowanie", key="no_features"):
            st.error("Wybierz co najmniej jednÄ… cechÄ™ do klastrowania.")

    # ReguÅ‚y asocjacyjne
    elif model_category == "ReguÅ‚y asocjacyjne":
        ml_info = get_ml_model_description("association_rules")
        section_header(ml_info["title"], "Odkrywanie interesujÄ…cych relacji miÄ™dzy cechami chemicznymi win")

        with st.expander("â„¹ï¸ O reguÅ‚ach asocjacyjnych"):
            st.markdown(ml_info["description"])

        # WybÃ³r cech
        st.subheader("WybÃ³r cech")

        # Pobierz kolumny numeryczne
        column_types = get_column_types(st.session_state.data)
        numeric_cols = column_types.get('numeric', [])

        # Widget do wyboru cech
        selected_features = st.multiselect(
            "Wybierz cechy do analizy:",
            numeric_cols,
            default=numeric_cols[:8] if len(numeric_cols) > 8 else numeric_cols,
            help="Wybierz cechy, miÄ™dzy ktÃ³rymi chcesz znaleÅºÄ‡ relacje"
        )

        # Parametry
        st.subheader("Parametry")

        # PrÃ³g binaryzacji
        threshold = st.slider(
            "PrÃ³g binaryzacji (percentyl):",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="WartoÅ›ci powyÅ¼ej tego percentyla bÄ™dÄ… traktowane jako 1, poniÅ¼ej jako 0"
        )

        # Wsparcie i pewnoÅ›Ä‡
        col1, col2 = st.columns(2)

        with col1:
            min_support = st.slider(
                "Minimalne wsparcie:",
                min_value=0.01,
                max_value=0.5,
                value=0.1,
                step=0.01,
                help="Minimalny procent obserwacji zawierajÄ…cych zbiÃ³r elementÃ³w"
            )

        with col2:
            min_confidence = st.slider(
                "Minimalna pewnoÅ›Ä‡:",
                min_value=0.5,
                max_value=1.0,
                value=0.7,
                step=0.05,
                help="Minimalna pewnoÅ›Ä‡ reguÅ‚y (wsparcie(X,Y) / wsparcie(X))"
            )

        # Lift i metryka
        col3, col4 = st.columns(2)

        with col3:
            min_lift = st.slider(
                "Minimalny lift:",
                min_value=1.0,
                max_value=5.0,
                value=1.2,
                step=0.1,
                help="Minimalna wartoÅ›Ä‡ liftu (wsparcie(X,Y) / (wsparcie(X) * wsparcie(Y)))"
            )

        with col4:
            metric = st.selectbox(
                "Metryka do sortowania reguÅ‚:",
                ["confidence", "lift", "leverage", "conviction"],
                index=1,
                help="""
                - Confidence: pewnoÅ›Ä‡ reguÅ‚y
                - Lift: jak bardziej prawdopodobne jest Y przy wystÄ…pieniu X
                - Leverage: rÃ³Å¼nica miÄ™dzy obserwowanym a oczekiwanym wsparciem
                - Conviction: jak wiele razy reguÅ‚a byÅ‚aby nieprawdziwa, gdyby X i Y byÅ‚y niezaleÅ¼ne
                """
            )

        # Tworzenie i trenowanie modelu
        if st.button("ZnajdÅº reguÅ‚y asocjacyjne", key="train_association_rules") and selected_features:
            # Przygotowanie danych
            X = st.session_state.data[selected_features]

            # Dodaj pasek postÄ™pu
            progress_bar = st.progress(0)
            status_text = st.empty()

            with st.spinner("Wydobywanie reguÅ‚..."):
                # Aktualizuj pasek postÄ™pu
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"Wydobywanie reguÅ‚ asocjacyjnych... {i + 1}%")
                    time.sleep(0.01)

                # Inicjalizacja modelu
                miner = AssociationRulesMiner()

                # Przygotowanie danych
                miner.prepare_data(X, threshold)

                # ZnajdÅº czÄ™ste zbiory elementÃ³w
                frequent_itemsets = miner.find_frequent_itemsets(min_support)

                # Generuj reguÅ‚y
                min_threshold = min_confidence if metric == 'confidence' else min_lift
                rules = miner.generate_rules(min_threshold, metric)

                # Ukryj pasek postÄ™pu i tekst statusu po zakoÅ„czeniu
                progress_bar.empty()
                status_text.empty()

                # WyÅ›wietl wyniki
                st.subheader("CzÄ™ste zbiory elementÃ³w")

                with st.expander("â„¹ï¸ Co to sÄ… czÄ™ste zbiory elementÃ³w?"):
                    st.markdown("""
                    **CzÄ™ste zbiory elementÃ³w** to grupy elementÃ³w (cech), ktÃ³re czÄ™sto wystÄ™pujÄ… razem.

                    W kontekÅ›cie Wine Dataset, element moÅ¼e oznaczaÄ‡ "cecha X ma wysokÄ… wartoÅ›Ä‡".
                    Na przykÅ‚ad, zbiÃ³r {Alcohol, Flavanoids} oznacza, Å¼e wina czÄ™sto majÄ… jednoczeÅ›nie
                    wysokÄ… zawartoÅ›Ä‡ alkoholu i flawonoidÃ³w.

                    Kolumna **support** pokazuje, jaki procent wszystkich win ma jednoczeÅ›nie wszystkie
                    elementy w danym zbiorze.
                    """)

                if frequent_itemsets is not None and not frequent_itemsets.empty:
                    st.write(f"Znaleziono {len(frequent_itemsets)} czÄ™stych zbiorÃ³w elementÃ³w.")

                    # PokaÅ¼ najczÄ™stsze zbiory
                    st.dataframe(frequent_itemsets.sort_values('support', ascending=False).head(20))
                else:
                    st.info("Nie znaleziono czÄ™stych zbiorÃ³w elementÃ³w z podanymi parametrami.")

                st.subheader("ReguÅ‚y asocjacyjne")

                with st.expander("â„¹ï¸ Jak interpretowaÄ‡ reguÅ‚y asocjacyjne?"):
                    st.markdown("""
                    **ReguÅ‚y asocjacyjne** majÄ… format "jeÅ›li X, to Y" (X â†’ Y):

                    - **X** (antecedents) to poprzednik/warunek
                    - **Y** (consequents) to nastÄ™pnik/konsekwencja

                    PrzykÅ‚ad: {wysokie_Alcohol, wysokie_Flavanoids} â†’ {wysokie_Proline}

                    Miary jakoÅ›ci reguÅ‚:
                    - **Support**: jaki procent wszystkich prÃ³bek zawiera zarÃ³wno X, jak i Y
                    - **Confidence**: jaki procent prÃ³bek zawierajÄ…cych X zawiera rÃ³wnieÅ¼ Y
                    - **Lift**: jak wiele razy bardziej prawdopodobne jest Y, gdy wystÄ™puje X

                    ReguÅ‚y z wyÅ¼szymi wartoÅ›ciami tych miar sÄ… bardziej interesujÄ…ce.
                    """)

                if rules is not None and not rules.empty:
                    st.write(f"Znaleziono {len(rules)} reguÅ‚ asocjacyjnych.")

                    # PokaÅ¼ najlepsze reguÅ‚y
                    top_rules = miner.get_top_rules(10, metric)
                    st.dataframe(top_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

                    # Sformatowane reguÅ‚y
                    st.subheader("Najlepsze reguÅ‚y (sformatowane)")
                    formatted_rules = miner.format_rules(top_rules)

                    for i, rule in enumerate(formatted_rules, 1):
                        st.write(f"{i}. {rule}")

                    # Wizualizacja reguÅ‚
                    st.subheader("Wizualizacja reguÅ‚ asocjacyjnych")

                    fig, ax = plt.subplots(figsize=(10, 8))

                    # Wybierz reguÅ‚y do wizualizacji
                    viz_rules = top_rules.head(15)

                    # StwÃ³rz etykiety dla reguÅ‚
                    rule_labels = [
                        f"{', '.join(list(r['antecedents']))} => {', '.join(list(r['consequents']))}"
                        for _, r in viz_rules.iterrows()
                    ]

                    # SkrÃ³Ä‡ dÅ‚ugie etykiety
                    rule_labels = [label[:50] + '...' if len(label) > 50 else label for label in rule_labels]

                    # Wykres wsparcia i pewnoÅ›ci
                    scatter = ax.scatter(
                        viz_rules['support'],
                        viz_rules['confidence'],
                        s=viz_rules['lift'] * 100,
                        alpha=0.6
                    )

                    # Dodaj etykiety dla punktÃ³w
                    for i, label in enumerate(rule_labels):
                        ax.annotate(
                            label,
                            (viz_rules['support'].iloc[i], viz_rules['confidence'].iloc[i]),
                            textcoords="offset points",
                            xytext=(0, 10),
                            ha='center',
                            fontsize=8
                        )

                    ax.set_xlabel('Wsparcie (support)')
                    ax.set_ylabel('PewnoÅ›Ä‡ (confidence)')
                    ax.set_title('ReguÅ‚y asocjacyjne: wsparcie vs pewnoÅ›Ä‡ (rozmiar = lift)')
                    ax.grid(True)

                    # Dodaj kolorowÄ… legendÄ™ dla liftu
                    handles, labels = scatter.legend_elements(
                        prop="sizes",
                        alpha=0.6,
                        func=lambda s: s / 100
                    )
                    ax.legend(handles, labels, title="Lift", loc="upper left")

                    st.pyplot(fig)

                    # Interpretacja wynikÃ³w
                    st.subheader("Interpretacja wynikÃ³w")
                    show_info_box("NajwaÅ¼niejsze wnioski", f"""
                    Z analizy reguÅ‚ asocjacyjnych moÅ¼na wyciÄ…gnÄ…Ä‡ nastÄ™pujÄ…ce wnioski:

                    1. **Najsilniejsze powiÄ…zania** wystÄ™pujÄ… miÄ™dzy: {', '.join([f"{','.join(list(r['antecedents']))} => {','.join(list(r['consequents']))}" for _, r in top_rules.head(3).iterrows()])}

                    2. **NajczÄ™stsze cechy** wystÄ™pujÄ…ce w reguÅ‚ach: {', '.join(set([item for _, row in top_rules.iterrows() for itemset in [row['antecedents'], row['consequents']] for item in itemset]))}

                    3. **Praktyczne zastosowanie**: ReguÅ‚y o wysokiej pewnoÅ›ci i lifcie mogÄ… byÄ‡ uÅ¼ywane do przewidywania cech chemicznych win na podstawie innych cech.

                    4. **InteresujÄ…ce wzorce**: Wina z wysokÄ… zawartoÅ›ciÄ… jednych zwiÄ…zkÃ³w czÄ™sto majÄ… rÃ³wnieÅ¼ wysokÄ… zawartoÅ›Ä‡ innych zwiÄ…zkÃ³w, co moÅ¼e odzwierciedlaÄ‡ procesy biochemiczne zachodzÄ…ce podczas produkcji wina.
                    """)
                else:
                    st.info("Nie znaleziono reguÅ‚ asocjacyjnych z podanymi parametrami.")

                    # Sugestie
                    st.warning("""
                    **Sugestie:**
                    - SprÃ³buj zmniejszyÄ‡ wartoÅ›Ä‡ minimalnego wsparcia
                    - SprÃ³buj zmniejszyÄ‡ wartoÅ›Ä‡ minimalnej pewnoÅ›ci lub liftu
                    - Wybierz wiÄ™cej cech do analizy
                    """)

        elif not selected_features and st.button("ZnajdÅº reguÅ‚y asocjacyjne", key="no_features_rules"):
            st.error("Wybierz co najmniej jednÄ… cechÄ™ do analizy.")

    # Podsumowanie
    st.markdown("---")
    st.subheader("PorÃ³wnanie metod uczenia maszynowego")

    with st.expander("ğŸ“š WskazÃ³wki wyboru odpowiedniej metody"):
        st.markdown("""
        ### Kiedy uÅ¼ywaÄ‡ rÃ³Å¼nych metod uczenia maszynowego:

        **Klasyfikacja:**
        - Gdy masz oznaczone dane (wiesz, do ktÃ³rej klasy naleÅ¼y kaÅ¼da prÃ³bka)
        - Gdy celem jest przewidywanie kategorii dla nowych prÃ³bek
        - Gdy chcesz zrozumieÄ‡, ktÃ³re cechy sÄ… najwaÅ¼niejsze dla rozrÃ³Å¼nienia klas

        **Klastrowanie:**
        - Gdy nie masz oznaczonych danych lub chcesz odkryÄ‡ naturalne grupowania
        - Gdy chcesz znaleÅºÄ‡ ukryte struktury lub segmenty w danych
        - Gdy chcesz zredukowaÄ‡ zÅ‚oÅ¼onoÅ›Ä‡ danych, grupujÄ…c podobne prÃ³bki

        **ReguÅ‚y asocjacyjne:**
        - Gdy chcesz odkryÄ‡ interesujÄ…ce relacje miÄ™dzy cechami
        - Gdy szukasz wzorcÃ³w wspÃ³Å‚wystÄ™powania cech
        - Gdy chcesz generowaÄ‡ reguÅ‚y, ktÃ³re moÅ¼na Å‚atwo interpretowaÄ‡

        ### WybÃ³r konkretnego algorytmu:

        **Random Forest:**
        - Dobrze radzi sobie z wieloma cechami
        - MoÅ¼e obsÅ‚ugiwaÄ‡ zarÃ³wno cechy numeryczne, jak i kategoryczne
        - Zapewnia miarÄ™ waÅ¼noÅ›ci cech

        **SVM:**
        - Dobrze dziaÅ‚a w przestrzeniach wysokowymiarowych
        - Efektywny, gdy liczba cech przewyÅ¼sza liczbÄ™ prÃ³bek
        - MoÅ¼e odkrywaÄ‡ nieliniowe granice decyzyjne

        **KNN:**
        - Prosty i intuicyjny
        - Nie wymaga trenowania
        - Dobry dla maÅ‚ych zbiorÃ³w danych

        **K-Means:**
        - Szybki i skalowalny
        - Åatwy do zrozumienia
        - DziaÅ‚a dobrze, gdy klastry majÄ… ksztaÅ‚t sferyczny

        **DBSCAN:**
        - MoÅ¼e wykrywaÄ‡ klastry dowolnego ksztaÅ‚tu
        - Automatycznie wykrywa wartoÅ›ci odstajÄ…ce
        - Nie wymaga z gÃ³ry okreÅ›lonej liczby klastrÃ³w
        """)

        # KoÅ„cowe podsumowanie
    show_info_box("Podsumowanie modelowania uczenia maszynowego", """
    **Najlepsze praktyki modelowania:**

    1. Przygotuj dane odpowiednio: Skaluj cechy dla wiÄ™kszoÅ›ci modeli, szczegÃ³lnie SVM i KNN
    2. Wybierz odpowiednie cechy: Nie wszystkie cechy sÄ… rÃ³wnie waÅ¼ne, czasem mniej cech daje lepsze wyniki
    3. Dostosuj parametry: KaÅ¼dy model ma parametry, ktÃ³re moÅ¼na dostosowaÄ‡ do konkretnego problemu
    4. Waliduj model: Zawsze oceniaj model na danych testowych, ktÃ³rych nie widziaÅ‚ podczas treningu
    5. Interpretuj wyniki: Sama dokÅ‚adnoÅ›Ä‡ to nie wszystko, waÅ¼ne jest zrozumienie, dlaczego model podejmuje takie decyzje

    NajwaÅ¼niejszym elementem jest dopasowanie algorytmu do problemu i danych, ktÃ³re masz.
    """)
